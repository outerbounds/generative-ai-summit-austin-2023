{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can change the response from the models without changing the models!\n",
    "\n",
    "In this lesson we will begin exploring ways to make LLM responses more relevant to end users. In traditional search applications, Google provides us a [variety](https://support.google.com/websearch/answer/35890?sjid=5982066035738547434-NA) [of](https://support.google.com/websearch/answer/142143?sjid=5982066035738547434-NA) [ways](https://blog.google/products/search/how-were-improving-search-results-when-you-use-quotes/) to make precise queries. LLMs are similar in that there are specific ways to write queries and influence LLMs whether ChatGPT, OpenAI APIs, or open-source models.\n",
    "\n",
    "You will see how to modify your ChatGPT interface to get it to do more of what you want, and we will also implement the same approach programmatically with a trending framework called [Langchain](https://python.langchain.com/docs/get_started/introduction).\n",
    "\n",
    "> \"In the vast majority of cases, we believe well-crafted prompts will get you the results you want\" - [Anthropic documentation](https://www.anthropic.com/product)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"display: block; float: center; max-width: 80%; height: auto; margin: auto; float: none!important;\" src=\"./relevance-blobs-1.png\"/>\n",
    "\n",
    "<br/>\n",
    "<center> A selection of ways to increase the relevance of LLM API responses - this notebook is about going from 1 to 2 </center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Messages\n",
    "\n",
    "System prompts are used to steer the way that ChatGPT responds to questions. Here is a [repo of examples](https://github.com/mustvlad/ChatGPT-System-Prompts).\n",
    "If you use ChatGPT regularly you should know about this.\n",
    "\n",
    "### Get started\n",
    "Open [ChatGPT](https://chat.openai.com/)\n",
    "\n",
    "In the \"What would you like ChatGPT to know about you to provide better responses?\" box:\n",
    "```\n",
    "You are a magical gnome that writes whimsical, yet highly informative poems about very boring topics in computer programming and business.\n",
    "```\n",
    "\n",
    "In the \"How would you like ChatGPT to respond?\" box:\n",
    "```\n",
    "Make rhymes.\n",
    "Make responses fun and lighthearted.\n",
    "Make responses precise and accurate.\n",
    "```\n",
    "\n",
    "Then ask a boring question about computer programming or business and see what happens!\n",
    "\n",
    "This is a silly example to help you get started, and [here](https://betterprogramming.pub/i-know-you-have-been-trained-up-to-2021-chatgpt-system-messages-explained-146a5513e753) is a more serious guide containing insights such as:\n",
    "- Clearly define the role you want ChatGPT to play\n",
    "- Clearly define the tone and format of the output\n",
    "- Be explicit and add context"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates\n",
    "Prompt templates are in the realm of recent tools like Langchain, designed to help us interface with LLMs.\n",
    "Essentially, prompt templates extend the idea of the system message into something like superpowered string formatting or jinja templating.\n",
    "\n",
    "> \"Prompt templates are pre-defined recipes for generating prompts for language models. A template may include instructions, few-shot examples, and specific context and questions appropriate for a given task.\" - [Langchain docs](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -qqq langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example from langchain docs: https://python.langchain.com/docs/get_started/quickstart\n",
    "\n",
    "# langchain dependencies\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI \n",
    "# See models - https://python.langchain.com/docs/integrations/chat/\n",
    "# Note: not all the models interact with system messages in the same way!\n",
    "# You have to learn about how the specific model you are interested in behaves.\n",
    "\n",
    "# create the template/format\n",
    "template = \"You are a helpful assistant that translates {input_language} to {output_language} with many years of experience teaching beginner language students.\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "\n",
    "chat = ChatOpenAI(openai_api_key=openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ich liebe Programmieren.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat(chat_prompt.format_messages(input_language=\"English\", output_language=\"German\", text=\"I love programming.\"))\n",
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
