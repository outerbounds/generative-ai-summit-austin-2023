{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting off the Ground with LLMs\n",
    "\n",
    "In this section, we will walk through how to access cutting-edge LLMs from your Python codes.\n",
    "We will walk through the basics of commercial APIs, open-source APIs, and a bit about their relative capabilities.\n",
    "\n",
    "## Commercial APIs\n",
    "\n",
    "If you don't have a plan, but want to build a language model-driven solution, commercial APIs are a good way to start.\n",
    "\n",
    "This section shows you how to get started with the leading commercial APIs as of October 2023:\n",
    "- [OpenAI](https://platform.openai.com/docs/api-reference)\n",
    "- [Cohere](https://docs.cohere.com/reference/about)\n",
    "- [Jurassic-2](https://docs.ai21.com/reference/python-sdk) from [A21 Labs](https://www.ai21.com/)\n",
    "- [Claude](https://github.com/anthropics/anthropic-sdk-python) from Anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -qqq openai cohere ai21 transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workspace/mambaforge/envs/sandbox-tutorial/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "### Notebook display\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "### Data processing\n",
    "import pandas as pd\n",
    "\n",
    "### Commerical LLM providers\n",
    "import openai\n",
    "import cohere\n",
    "import ai21\n",
    "\n",
    "### Open-source LLMs\n",
    "from transformers import AutoModel, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set API Keys\n",
    " \n",
    "Go to these links to find your tokens (after signing up):\n",
    "- [OpenAI](https://platform.openai.com/account/api-keys)\n",
    "- [Cohere](https://dashboard.cohere.com/api-keys)\n",
    "- [A21 Labs](https://studio.ai21.com/account/api-key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key = ...\n",
    "cohere_key = ...\n",
    "ai21_key = ...\n",
    "# Note: Did not include Claude here, as SDK/API access is gated: https://docs.anthropic.com/claude/docs/getting-access-to-claude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The common prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"How is generative AI affecting the infrastrucutre machine learning developers need access to?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hello OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = openai_key\n",
    "gpt35_completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[{\"role\": \"user\", \"content\": PROMPT}]\n",
    ")\n",
    "gpt35_text_response = gpt35_completion.to_dict()['choices'][0]['message']['content'].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hello Cohere API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = cohere.Client(cohere_key)\n",
    "cohere_cmd_completion = co.generate(prompt=PROMPT, model=\"command\")\n",
    "cohere_cmd_response = cohere_cmd_completion.data[0].text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hello A21 Labs API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai21.api_key = ai21_key\n",
    "jurassic2_completion = ai21.Completion.execute(\n",
    "    model=\"j2-mid\", \n",
    "    prompt=PROMPT,\n",
    "    maxTokens=250,\n",
    ")\n",
    "jurassic2_response = jurassic2_completion.completions[0]['data']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**OpenAI GPT3.5**: Generative AI is significantly impacting the infrastructure requirements for machine learning developers. Traditionally, machine learning development focused on supervised learning, where large amounts of labeled data were required. This necessitated the need for extensive compute resources and storage to handle the data processing and training tasks.\n",
       "\n",
       "However, generative AI, which includes techniques like generative adversarial networks (GANs) and transformers, has revolutionized this paradigm. It enables the generation of new data samples, such as images, text, or even complete programs, without the need for extensive manual labeling. This has several implications for infrastructure:\n",
       "\n",
       "1. Computing power: Training generative models can be computationally intensive and often requires powerful hardware, such as GPUs or even specialized hardware like TPUs (Tensor Processing Units). Developers need access to these resources to train and fine-tune generative models effectively.\n",
       "\n",
       "2. Data storage and management: Generative models typically require large-scale datasets, which need to be stored and efficiently managed. Handling significant amounts of data necessitates scalable storage systems that provide fast access and retrieval speeds.\n",
       "\n",
       "3. Data preprocessing: Preparing data for generative AI involves various preprocessing steps like cleaning, augmentation, and formatting. This requires efficient data processing frameworks that can handle these operations at scale.\n",
       "\n",
       "4. Model sharing and collaboration: As the field advances, developers need platforms and infrastructure to share pretrained models, collaborate on model development, and perform model evaluations. This requires robust infrastructure to host and distribute the models and frameworks to organize collaboration effectively.\n",
       "\n",
       "5. Real-time inference: Deploying generative models in real-time applications necessitates low-latency inference. This requires efficient model serving infrastructure that can handle high-throughput requests and respond quickly.\n",
       "\n",
       "Overall, generative AI has increased the demand for infrastructure resources, including powerful compute, efficient data management, preprocessing tools, collaborative platforms, and real-time deployment capabilities. Machine learning developers need access to such resources to effectively experiment, train, and deploy generative models.\n",
       "\n",
       "================================================================================================================================================================\n",
       "\n",
       "**Cohere Command**: As generative AI grows in popularity, it is placing greater emphasis on the infrastructure that machine learning developers require. In particular, the increasing demand for high-performance computing resources like GPUs and TPUs is necessitating a rethinking of how these resources are delivered.\n",
       "\n",
       "Currently, cloud providers such as Google, Microsoft, and Amazon are bolstering their infrastructure to better support generative AI. This includes upgrades to their hardware as well as the development of new services and products that are specifically tailored for generative AI workloads. For instance, Google has released the generative AI cloud service AI Hub, while Microsoft has created the Azure AI Platform. \n",
       "\n",
       "In addition to cloud providers, hardware manufacturers like NVIDIA and AMD are developing more specialized hardware for generative AI. This includes chips that are designed specifically for AI workloads, such as NVIDIA's A100 and AMD's Radeon Instinct.\n",
       "\n",
       "As the demand for generative AI continues to rise, it is likely that we will see further developments in the infrastructure that machine learning developers need to access. This includes improvements to both hardware and software, as well as the creation of new tools and services that are specifically designed for generative AI.\n",
       "\n",
       "================================================================================================================================================================\n",
       "\n",
       "**AI21 Jurassic2**: \n",
       "Generative AI is a branch of machine learning that aims to create artificial models that can generate new synthetic data or patterns based on learned data. This technology has the potential to significantly impact the infrastructure that machine learning developers need access to, as it requires large amounts of data and complex computational resources. Here are some ways in which generative AI is affecting the infrastructure required by machine learning developers:\n",
       "\n",
       "1. Enhanced Data Collection: Generative AI requires large amounts of data to learn from and create new patterns. As a result, there is a growing demand for data collection efforts and the ability to store and manage vast amounts of data. This requires robust data storage infrastructure, including databases and file systems that can handle the large volumes of data.\n",
       "\n",
       "2. Increased Computing Power: Generative AI models are highly computationally intensive and require very powerful computing infrastructure, such as high-performance computing (HPC) systems or cloud clusters. These computing resources are used to train and fine-tune the models, as well as to generate new patterns and data. Machine learning developers need access to adequate computing infrastructure to train and run these models effectively.\n",
       "\n",
       "3. Data Processing and Preprocessing: Generative AI models are complex and require preprocessing and manipulation of raw data. This includes tasks such as normalizing the data, handling missing values, and converting data types. Developers need infrastructure that can handle these preprocessing tasks quickly and efficiently, and that enables the integration of various data sources.\n",
       "\n",
       "4. Model Training and Evaluation: Training and evaluating generative AI models is computationally intensive and requires significant resources. This includes access to computing infrastructure that can handle the iterative nature of model training, as well as the parallelization of computations to maximize performance.\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(f\"\"\"\n",
    "\n",
    "**OpenAI GPT3.5**: {gpt35_text_response}\n",
    "\n",
    "{\"=\"*160}\n",
    "\n",
    "**Cohere Command**: {cohere_cmd_response}\n",
    "\n",
    "{\"=\"*160}\n",
    "\n",
    "**AI21 Jurassic2**: {jurassic2_response}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint support across APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **rough** picture of what endpoints these APIs have available as of October 20, 2023, without much more effort than what you just saw.\n",
    "\n",
    "> Note: You can make each of these models do almost anything, making this all muddy. <br/>The point of this table is to highlight which of these APIs have documented endpoints for certain tasks.\n",
    "\n",
    "<center>\n",
    "\n",
    "| Endpoint / API | OpenAI | Cohere | Claude | A21 |\n",
    "| :---: | :---: | :---: | :---: | :---: |\n",
    "| Prompt-to-response | ✅ | ✅ | ✅ | ✅ |\n",
    "| Chat-to-response | ✅ | ✅ | ✅ | ✅ |\n",
    "| Text embeddings | ✅ | ✅ | ❌ | ✅ |\n",
    "| Fine-tuning | ✅ | ✅ | ❌ | ✅ |\n",
    "| Language detection | ❌ | ✅ | ❌ | ❌ |\n",
    "| Raw document processing | ✅ | ✅ | ❌ | ✅ | \n",
    "| Rerank / document relevance | ❌ | ✅ | ❌ | ✅ |\n",
    "| Text/image to image | ✅ | ❌ | ❌ | ❌ |\n",
    "| Audio-to-text | ✅ | ❌ | ❌ | ❌ |\n",
    "| Moderations / toxicitiy | ✅ | ✅ | ❌ | ❌ | \n",
    "\n",
    "</center>\n",
    "\n",
    "Some opinions related to this table:\n",
    "- If you want to pay for the **best chat model** --> \n",
    "    - OpenAI's GPT4 API is the current gold standard.\n",
    "- If you want **multimodal** --> \n",
    "    - OpenAI APIs are great - [Images](https://platform.openai.com/docs/api-reference/images), [Audio](https://platform.openai.com/docs/api-reference/audio)\n",
    "    -  Stability AI has some nice products not listed here. \n",
    "    - Check out this recent survey paper: [The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)](https://arxiv.org/abs/2309.17421)\n",
    "- If you care a lot about **content moderation** --> \n",
    "    - [Cohere](https://docs.cohere.com/docs/content-moderation-with-classify) and [OpenAI](https://platform.openai.com/docs/api-reference/moderations) have the most API support\n",
    "- If you want fine-grained **multi-lingual models** --> \n",
    "    - Try Cohere's [Multilingual Embedding](https://docs.cohere.com/docs/multilingual-language-models) APIs\n",
    "- If you want a model that can **analyze grammar** --> \n",
    "    - Try A21's [Text Improvements](https://docs.ai21.com/reference/text-improvements-api-ref) and [Grammatical Error Corrections](https://docs.ai21.com/reference/gec-api-ref) APIs\n",
    "- The public Claude product is a personal favorite, however their API access and feature support is lacking behind others in this list\n",
    "\n",
    "Of course, you can also try meshing them together if you have the budget and engineering will!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Open-source Models\n",
    "\n",
    "## Discussion\n",
    "- Why would you want to use open-source LLMs?\n",
    "- Will they ever really be competitive? \n",
    "    - What drives the competition if OpenAI's models are 10x bigger and performance keeps scaling with model size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model\n",
    "\n",
    "In this section we will see how to load a pre-trained model from the HuggingFace Hub. \n",
    "You can shop for models [here](https://huggingface.co/models).\n",
    "\n",
    "After, you'll see how to use these models for text classification and text generation, similar to the core mechanism of how the commerical APIs you saw above are generating text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T5 paper: https://arxiv.org/pdf/2210.11416.pdf\n",
    "model_name = \"t5-small\"\n",
    "model = AutoModel.from_pretrained(model_name, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5Model(\n",
      "  (shared): Embedding(32128, 512)\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 8)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-5): 5 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 8)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-5): 5 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to learn more about transformers like the BERT and GPT family and how they work? \n",
    "- Sebastian Raschka recently gave his description of the history of the transformer in this concise [post](https://www.linkedin.com/posts/sebastianraschka_llms-largelanguagemodels-ai-activity-7121484400701186048--47t?utm_source=share&utm_medium=member_desktop).\n",
    "- Check out the amazing [Bertviz](https://github.com/jessevig/bertviz) tool by [jessevig](https://github.com/jessevig/). you can see a pre-loaded demo [here](https://colab.research.google.com/drive/1hXIQ77A4TYS4y3UthWF-Ci7V7vVUoxmQ?usp=sharing#scrollTo=twSVFOM9SopW)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuggingFace Pipeline API\n",
    "\n",
    "In the previous section we saw how to load a model, in this section we see the easiest way to use HuggingFace models for inference like with the earlier examples using commercial APIs.\n",
    "\n",
    "You will see how the [HuggingFace Pipeline API](https://huggingface.co/docs/transformers/v4.34.0/en/main_classes/pipelines) perform tasks including:\n",
    "* [Text Classsification](#text-classification)\n",
    "* [Text Generation](#text-generation)\n",
    "* many more tasks [here](https://huggingface.co/tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation\n",
    "https://huggingface.co/tasks/text-generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bigscience/bloom-560m\" # https://huggingface.co/bigscience/bloom-560m\n",
    "generator = pipeline(\"text-generation\", model=model_name, device_map=\"auto\")\n",
    "\n",
    "prompt = \"The Generative AI World Summit is a\" \n",
    "response = generator(prompt, do_sample=False, max_new_tokens=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(f\"\"\"\n",
    "**Prompt**: {prompt}\n",
    "\n",
    "**{model_name}'s continuation**: {response[0]['generated_text']}...\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification\n",
    "https://huggingface.co/tasks/text-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'excitement', 'score': 0.24082745611667633},\n",
       " {'label': 'admiration', 'score': 0.5622110366821289},\n",
       " {'label': 'curiosity', 'score': 0.5444050431251526},\n",
       " {'label': 'neutral', 'score': 0.5019526481628418}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More text classification models: https://huggingface.co/models?pipeline_tag=text-classification&sort=trending\n",
    "model_name = \"SamLowe/roberta-base-go_emotions\" \n",
    "\n",
    "# Create a text classification pipeline using HuggingFace transformers pipeline.\n",
    "classifier_pipe = pipeline(\"text-classification\", model=model_name)\n",
    "\n",
    "# Sample data we want to classify the sentiment of.\n",
    "sentences = [\n",
    "    \"I am feeling inspired today. What a time to be alive!\",\n",
    "    \"This talk is informative, but a bit high-level, where I can find more details?\",\n",
    "    \"I wonder about all the hype around Generative AI, is it smoke and mirrors?\",\n",
    "    \"Building production-grade machine learning systems is challenging.\"\n",
    "]\n",
    "\n",
    "# Run the pipeline!\n",
    "classifier_pipe(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this lesson, you've learned:\n",
    "- how to programmatically query the leading commercial generative AI APIs\n",
    "- which endpoints are supported by the leading generative AI APIs\n",
    "- how to get started with replicating the core modeling loops of generative AI using open-source\n",
    "\n",
    "In the next lessons we will discuss methods for increasing the relevance of LLM responses, starting with basic prompt engineering, retrieval-augmented generation (RAG), and changing the model itself through fine-tuning and serving it behind an API you can control."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
